---
layout: post
title: Milestone 2
---

## Table des matières

1. [Ingénierie des caractéristiques I](#ingenierie_des_caracteristiques_1)
2. [Suivi des expériences](#suivi_experiences)
3. [Modèles de base](#modeles_de_base)
4. [Ingénierie des caractéristiques II](#ingenierie_des_caracteristiques_2)
5. [Modèles avancés](#modeles_avances)
6. [Meilleur modèle (Faites de votre mieux!)](#meilleur_modele)
7. [Évaluer sur l'ensemble de test](#evaluer_ensemble_test)

## 1. Suivi des expériences

## 2. Ingénierie des caractéristiques I

#### Histogramme A  
Un Transformation de type **sqrt** a été fait pour pouvoir regarder mieux la distribution des petits valeurs  
![Q21a_histo](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/Q21a_histo.png)  

#### Histogramme B
![Q21b_histo](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/Q21b_histo.png)  

#### Graphe 2d
![Q21c_graph](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/Q21c_graph.png)  

#### Graphe comparaison (Distance et Angle)
![Q22_graph](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/Q22_graph.png)  

#### Histogramme Filet vide ou pas
![Q23_histo](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/Q23_histo.png)  

## 3. Modèles de base

Notre premier modèle de base (entraîné seulement avec la distance par rapport au but) a une précision de 0.905. Or, quand nous regardons les prédictions de notre modèle, 
nous remarquons qu'il prédit toujours qu'un tir ne résultera pas en un but. Évidemment, comme la plupart des tirs ne résultent pas en un but, notre modèle obtient
une excellente précision. Toutefois, nous souhaitons être capable de prédire les buts. Pour la suite de l'expérience, il nous faudra donc procéder
à un rééquilibrage des données.

## 4. Ingénierie des caractéristiques II
Liste des caractéristiques créées:

<ul>
  <li> period_sec: Nombre total de secondes restantes à la période lorsque l'événement a lieu </li>
  <li> period: Numéro de la période de jeu durant laquelle l'événement a lieu </li>
  <li> x:  Coordonnée x de l'événement </li>
  <li> y: Coordonnée y de l'événement </li>
  <li> goal_distance: Distance de tir par rapport au but pour les événements ['Shot', 'Goal'] </li>
  <li> angle: Angle de tir par rapport au but entre 0 et 180 degrés pour les événements ['Shot', 'Goal'] </li>
  <li> last_event: Dernier type d'événement </li>
  <li> last_x: Coordonnée x du dernier événement </li>
  <li> last_y: Coordonnée y du dernier événement </li>
  <li> time_since_last: Temps écoulé depuis le dernier événement </li>
  <li> last_distance: Distance entre l'événement présent et le dernier événement </li>
  <li> rebound: Indique si le dernier événement est 'Shot' ou non </li>
  <li> change_angle: Différence d'angle, en valeur absolue, entre l'événement présent et le dernier événement si ces deux événements sont 'Shot' </li>
  <li> speed: Ratio entre la distance parcourue et le temps écoulé depuis le dernier événement </li>
</ul>

Voici le lien vers l'expérience qui stocke l'artefact DataFrame filtré: https://www.comet.com/jhd/project-ds-ift6758-a23/5ea27708dda94f978f538c1bd1c3a72b?assetId=046136edf7ba4a88b41a4543d824da6e&assetPath=dataframes&experiment-tab=assetStorage

## 5. Modèles avancés

#### 5.1 XGBoost avec les caractéristiques des base
Nous avons premièrement entraîné un modèle XGBoost en n'utilisant que les caractéristiques de distance et d'angles...(TODO)

#### 5.2 XGBoost avec nos nouvelles caractéristiques et avec des hyperparamètres optimisés
Nous avons ensuite entraîné un modèle XGBoost avec les caractéristiques créées dans la section 4. Nous avons créé une fonction se servant d'un hypercube latin afin de trouver le meilleur choix d'hyperparamètres. Notre meilleure combinaison d'hyperparamètres maximise les résultats obtenus pour les métriques de balanced accuracy, de f1 weighted, de recall_weighted et de roc auc. Voici les hyperparamètres sélectionnés:

<ul>
  <li>learning_rate: 0.726847</li>
  <li>n_estimators: 70</li>
  <li>max_depth: 42</li>
  <li>min_child_weight: 10</li>
  <li>subsample: 0.91968</li>
  <li>colsample_bytree: 0.228184</li>
  <li>reg_alpha: 0.650468</li>
  <li>max_delta_step: 4</li>
  <li>min_split_loss: 7.684902</li>
</ul>

#### 5.3 XGBoost avec sélection de caractéristiques
Nous nous sommes servis de différentes méthodes afin de déterminer l'importance de nos caractéristiques. Nous avons utilisé la librairie eli5 afin d'obtenir une première mesure sur l'importance des caractéristiques.

![eli5](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/eli5_2.jpg)

Les caractéristiques d'importances sont emptyNet, last_x, last_distance, change_angle et angle. 

![emptyNet](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/emptyNet_plot.png)

Il est évident que de savoir si un but est vide ou non est un indicateur fort pour nos prédictions. Le graphique précédent nous montre qu'un but vide résulte plus souvent en un but. Dans le cas où le gardien est devant le filet cependant, nous n'obtenons aucune information pertinente. Notre caractéristique est alors sans importance.

![last_x](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/last_x_plot.png)

La caractéristique last_x fait référence à la position en x de la dernière action. Il semble que les actions menées au coeur de la patinoire (autour de la ligne du centre) sont les plus déterminantes pour prédire un but à venir.

![last_distance](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/last_distance_plot.png)

Il semble aussi que plus l'action précédente a eu lieu à une faible distance de l'action présente, plus celle-ci augmente l'importance de la caractérisque last_distance.

![shap0](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/shap_0.jpg)

Nous avons également effectué une analyse avec shap. Nous voyons qu'un tir rapproché effectué à 15.3 pieds du but augmenter les chances de marquer. Dans notre cas, lorsque last_event est égal à 1 cela signifie que le dernier événement était un but. Ainsi, nous voyons que lorsque le dernier événement était un but, cela diminue les chances que l'événement présent soit aussi un but. Ce résultat est logique, puisqu'après un but le jeu arrête, puis reprend au centre de la patinoire. 

Par ailleurs, nous nous sommes posés la question à savoir si notre test eli5 arrivait réellement à juger de l'importance des caractéristiques. Nous avons donc sélectionné 8 caractéristiques sur les 12 que nous avions évalué précédemment afin de créer un nouveau classement. Nous avons entre autres enlevé emptyNet, car bien qu'un filet vide soit un indicateur fort pour nos prédictions, il s'agit d'un événement rare. La figure ci-bas montre nos résultats.

![eli5](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/eli5.jpg)

Notre analyse effectuée avec notre modèle XGBoost entraîné sur les 8 caractéristiques listées dans la figure ci-haut indique que "time_since_last", "goal_distance" et "speed" sont nos trois caractéristiques les plus importantes. Il est intéressant de noter que cette fois-ci, last_x et last_distance sont relativement bas dans le classement. Nous avons effectué une analyse d'indépendance partielle sur nos trois premières caractéristiques.

![time_since_last](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/time_since_last_plot.png)

Nous voyons que lorsque moins de 5 secondes se sont écoulées depuis le dernier événement, l'importance de la caractéristique "time_since_last" est très forte pour nos prédictions. Une explication plausible serait que plusieurs tirs effectués rapidement l'un à la suite de l'autre sont plus difficiles à arrêter pour un gardien de but et augmentent ainsi la chance de marquer un but. 

![goal_distance](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/goal_distance_plot.png)

Nous voyons que plus un tir est effectué près d'un but, plus la distance est importante comme caractéristique. Les tirs rapprochés ont plus de chance de résulter en un but comme nous l'avons vu dans le milestone 1. Ce graphique rejoins donc l'analyse que nous avions formulée initialement.

![speed](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/speed_plot.png)

Le "speed" est défini comme comme la distance depuis l'événement précédent, divisée par le temps écoulé depuis l'événement précédent. Notre graphique est difficile à interpréter. En effet, on pourrait supposer que des tirs qui se suivent rapidement dans le temps et dans l'espace ont plus de chance de résulter en un but. Au contraire, on pourrait supposer que des tirs qui ne se suivent pas rapidement dans le temps et dans l'espace ont moins de chance de résulter en un but. 

![eli5](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/shap.jpg)

Nos valeurs shap montrent qu'une faible distance par rapport au but (goal_distance) augmente la probabilité d'un but. Un angle de 131.6 degrés diminue la probabilité qu'un tir résulte en un but, ce qui est logique puisque la surface du filet qui peut être atteinte par un tir diminue quand l'angle s'éloigne de 90 degrés.

Ceci nous amène à un autre entraînement que nous avons effectué. Nous avons décider de garder  4 de nos caractéristiques de départ, soit 'emptyNet', 'last_distance', 'change_angle' et 'angle'. Nous avons sélectionné les hyperparamètres choisis en 5.2. 

## 6. Meilleur modèle (Faites de votre mieux!)

Nous avons tenté d'optimiser un modèle de Random Forest Classifier en utilisant une méthode de sélection des caractéristique vue en classe. Nous avons en effet en effet implémenté une méthode d'encapsulation de type recherche vers l'avant. Pour ce faire, nous avons sélectionné la meilleure caractéristique parmi 16 caractéristiques en se basant sur un score de f1 weighted. En effet, comme nous l'avons déjà mentionné, l'accuracy n'est pas la meilleure métrique dans notre cas. Ensuite, nous avons tenté de trouver la caractéristique qui optimisait le f1 weighted dans un entrainement effectué en combinaison avec la première caractéristique. Nous avons procéder de la sorte pour trouver 6 caractéristiques. Les 6 caractéristiques ainsi sélectionnées sont les suivantes : emptyNet', 'y', 'x', 'periodTimeRemaining', 'speed' et 'time_since_last'.

Comme deuxième modèle, nous avons construit un classifieur dont les prédictions de probabilités sont déterminées par la moyenne (possiblement pondérée) de deux modèles XGBoost différents (soft voting). Ces deux modèles XGBoost se distinguent l'un de l'autre à travers la différence dans les hyperparamètres et random states utilisés durant leur entrainement respectif. Pour ce faire, nous avons commencé par remplacer les valeurs manquantes et les valeurs infinies par 0. Nous avons essayé de remplacer celles-ci par le mode, la médiane ou la moyenne des distributions respectives, mais les modèles résultants performaient moins bien que si on remplaçait par 0. Ensuite, dans un premier temps, au niveau de la sélection de caractéristiques nous avons procédé en entrainant un modèle XGBoost avec hyperparamètres standard à l'exception du scale_pos_weight qui a été fixé à 10. Puis, nous avons regardé à la fois l'importance des caractéristiques produite par ce modèle, l'importance par permutation des caractéristiques résultante de ce modèle et la matrice de corrélations des caractéristiques pour éviter la redondance. Les visualisations de ces métriques sont explicités ci-dessous:

{% include Feat_imp_voting_algo.png %}
{% include Feat_perm_voting_algo.png %}
{% include Corr_Heatmap_voting_algo.png %}

On remarque qu'on a inclut dans nos données une variable aléatoire qui nous permet de mettre de côté certaines caractéristiques négligeables.  Ainsi, à partir de ces 3 figures, nous avons pu réduire notre liste de caractéristiques à 8 caractéristiques: 'emptyNet', 'goal_distance', 'time_since_last',
'angle', 'y', 'shot_type', 'last_distance' et 'speed'. Une fois cette liste de caractéristiques finale obtenues, nous avons roulé deux fois, avec des états aléatoires différents, la recherche d'hyperparamètre par hypercube latin en combinaison avec la validation croisée (sur l'ensemble d'entrainement) afin de trouver les hyperparamètres optimaux de chacun des deux modèles XGBoost. Finalement, nous avons reséparé les données et réentrainer le modèle combiné (les deux XGBoost) pour pouvoir produire les métriques de validations de celui-ci. Les prédictions utilisées pour les métriques de validation ont été obtenues en effectuant la moyenne exact des prédictions de probabilités des deux modèles. Celui-ci a bien performé par rapport au modèle précédent. Entre autres, il a obtenu un ROC AUC score de 0.77. 

## 7. Évaluer sur l'ensemble de test
