---
layout: post
title: Milestone 2
---

## Table des matières

1. [Suivi des expériences](#suivi_experiences)
2. [Ingénierie des caractéristiques I](#ingenierie_des_caracteristiques_1)
3. [Modèles de base](#modeles_de_base)
4. [Ingénierie des caractéristiques II](#ingenierie_des_caracteristiques_2)
5. [Modèles avancés](#modeles_avances)
6. [Meilleur modèle (Faites de votre mieux!)](#meilleur_modele)
7. [Évaluer sur l'ensemble de test](#evaluer_ensemble_test)

## 1. Suivi des expériences

Pour mieux suivre nos expériences et favoriser la reproductibilité, nous avons enregistré nos expériences sur [Comet](https://www.comet.com/jhd/project-ds-ift6758-a23-2/view/new/panels)

## 2. Ingénierie des caractéristiques I

#### Histogramme 1A  
Un Transformation de type **sqrt** a été fait pour pouvoir mieux visualiser la distribution des petits valeurs  
![Q21a_histo](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/Q21a_histo.png)

Sans surprise, nous observons que davantage de buts sont marqués près du filet. Par ailleurs, la plupart des tirs sont effectués dans la zone offensive. 

#### Histogramme 1B
![Q21b_histo](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/Q21b_histo.png)

Avant tout, notons que dans notre graphique, 90 degrés signifie un angle perpendiculaire au filet. Nous avons calculé les angles dans le sens des aiguilles d'une montre. Par rapport à notre filet, que nous considérons comme une droite, 0 degrés indique la droite et 180 degrés indique la gauche. Nous observons que le nombre de tirs et de buts diminuent au fur et à mesure que nous nous éloignons de 90 degrés. Cette distribution s'explique probablement par le fait que les tirs en angle sont plus difficiles, car ils ne peuvent atteindre qu'une fraction du filet. Les équipes ont avantage à favoriser les tirs depuis 
le centre (sur l'axe des y) de la patinoire.

#### Graphe 1C 
![Q21c_graph](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/Q21c_graph.png)  

Nous observons que les tirs éloignés se font plus souvent à 90 degrés, ce qui est logique, car plus on s'éloigne du filet adverse, plus l'angle de tir possible le plus éloigné de 90 degrés diminue. On peut penser par exemple aux tirs à 0 degrés ou à 175 degrés qui sont ne sont possibles que près du but. Nous observons que la distribution des données semble indiquer qu'autant de tirs sont envoyés de la droite et de la gauche de la patinoire. Par ailleurs, nous voyons que davantage de buts sont marqués près du filet.

#### Graphe 2 (comparaison distance et angle)
![Q22_graph](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/Q22_graph.png)

Nous observons un fort taux de succès des tirs près du filet, ce qui corrobore les résultats de notre histogramme 1A. Cependant, nous voyons un fort taux de succès des tirs effectués de loin. Le taux de succès est élevé, mais comme nous le voyons dans notre histogramme 1A, il s'agit d'un événement moins fréquent que les tirs rapprochés. Nous supposons que certains de ces tirs sont effectués sur des filets vides, mais que somme toutes nous avons probablement certaines données aberrantes comme nous le verrons au point suivant. Pour ce qui est de l'angle du tir, nous voyons comme dans notre histogramme 1B que les tirs effectués en angle ont un taux de succès inférieur.

#### Graphe 3 (Histogramme Filet vide ou pas)
![Q23_histo](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/Q23_histo.png)

Les données ici semblent cohérentes avec nos hypothèses et nos graphiques précédents, à l'exception des 476 buts marqués dans un filet non vide à une distance entre 150 et 175 pieds du but adverse. Soit nous avons commis une erreur de méthodologie, soit nous avons quelques données aberrantes. Une explication possible est que les tirs sont parfois enregistrés du mauvais côté de la patinoire. Nous avons à ce sujet remarqué que pour la partie 2019030414, Corey Perry est censé avoir marqué un but à 176.003 pieds du filet adversaire. Or, en regardant la vidéo de reprise disponible sur le [Game Center](https://www.nhl.com/gamecenter/dal-vs-tbl/2020/09/25/2019030414) de la NHL, nous remarquons que le but a été marqué très près du filet adversaire (moins de 5 pieds). Il semble donc que certaines données soient mal compilées par la NHL. Par ailleurs, le type de tir est un Tip-In. C'est-à-dire que Corey Perry a "poussé" la rondelle dans le but. Nous pouvons donc expliquer certaines données aberrantes du Milestone 1, où avions trouvé des buts marqués par un tir de type "Tip-In" à une distance éloignée. Il s'agissait probablement de données aberrantes telle que celle indiquée ici. Par ailleurs, nous observons que les filets non vides sont un événement rare.

## 3. Modèles de base

Notre premier modèle de base (entraîné seulement avec la distance par rapport au but) a une précision de 0.905. Or, quand nous regardons les prédictions de notre modèle, nous remarquons qu'il prédit toujours qu'un tir ne résultera pas en un but. Évidemment, comme la plupart des tirs ne résultent pas en un but, notre modèle obtient une excellente accuracy. Toutefois, nous souhaitons être capable de prédire les buts. Pour la suite de l'expérience, il nous faudra donc procéder
à un rééquilibrage des données et aussi considérer de nouvelles métriques.

Note pour lire les graphiques (avec liens vers l'expérience sur Comet):

- [1.0.0 : classificateur aléatoire](https://www.comet.com/jhd/project-ds-ift6758-a23-2/f1aad054759d4eacb797fd6cefbe1d02)
- [1.1.0 : Régression logistique, entraînée sur la distance uniquement](https://www.comet.com/jhd/project-ds-ift6758-a23-2/2b876cd4fcb0494180b103a87f9501de)
- [1.2.0 : Régression logistique, entraînée sur l'angle uniquement](https://www.comet.com/jhd/project-ds-ift6758-a23-2/4ab67cf83ce0479db007e6a2237840ef)
- [1.3.0 : Régression logistique, entraînée sur la distance et l'angle](https://www.comet.com/jhd/project-ds-ift6758-a23-2/4727a86f42ec4f55a85c762d70e97fef)


![image](https://s3.amazonaws.com/comet.ml/image_baf30ac5cb8044f48cb1c44ecde1e9ab-cwfMh7yXy5xyW8caahuvxoaAG.svg)
Les valeurs AUC des courbes indiquent que les versions 1.2.0 et 1.3.0 sont meilleures que les deux autres versions. Cela est attendu pour la version 1.3.0 puisqu'il y a plus de caractéristiques.
![image](https://s3.amazonaws.com/comet.ml/image_baf30ac5cb8044f48cb1c44ecde1e9ab-GCeY7k8r7dlR0RpF4ldRlZZ0l.svg)
Pour des données imbalancées dans un problème de classification, la courbe de précision-rappel est intéressante puisqu'elle représente le compromis entre deux métriques. Ici plus l'air en dessous des courbes est grand,  meilleures sont les valeurs de métrique. Selon le graphique ci-dessous, la version 1.1.0 semble avoir la plus grande aire sous la courbe. Autrement dit, cette version retourne des prédictions précises et dont la majorité de ces prédictions positives sont pour des cas positifs.
![image](https://s3.amazonaws.com/comet.ml/image_baf30ac5cb8044f48cb1c44ecde1e9ab-jEqwN3tOSDIjO4mZcVZKFB6g6.svg)
Il est intéressant de noter que seule la caractéristique d'angle n'est pas une bonne caractéristique puisque la version 1.2.0 est très similaire au modèle aléatoire.
![image](https://s3.amazonaws.com/comet.ml/image_baf30ac5cb8044f48cb1c44ecde1e9ab-hw6amQYv24CgKLInHr3EHwzKD.svg)
![image](https://s3.amazonaws.com/comet.ml/image_baf30ac5cb8044f48cb1c44ecde1e9ab-90CUeR3Dz4neh7VdGsWRP9GvU.svg)
Le modèle 1.3.0 sous-estime la probabilité qu'un tir soit un but. Les autres versions semblent qu'un seul point sur la droite pointillée et il est donc difficile d'argumenter sur la calibration.

Dans nos graphes, mous voyons mal le modèle entraîné sur la distance uniquement, car sa courbe est sous celle de notre modèle de régression logistique entraînée sur la distance et l'angle. Ces deux modèles performent mieux que notre modèle aléatoire, contrairement à notre modèle entraîné sur l'angle uniquement qui obtient un résultat très semblable à notre modèle aléatoire.

## 4. Ingénierie des caractéristiques II
Liste des caractéristiques créées:

<ul>
  <li> period_sec: Nombre total de secondes restantes à la période lorsque l'événement a lieu </li>
  <li> period: Numéro de la période de jeu durant laquelle l'événement a lieu </li>
  <li> x:  Coordonnée x de l'événement </li>
  <li> y: Coordonnée y de l'événement </li>
  <li> goal_distance: Distance de tir par rapport au but pour les événements ['Shot', 'Goal'] </li>
  <li> angle: Angle de tir par rapport au but entre 0 et 180 degrés pour les événements ['Shot', 'Goal'] </li>
  <li> last_event: Dernier type d'événement </li>
  <li> last_x: Coordonnée x du dernier événement </li>
  <li> last_y: Coordonnée y du dernier événement </li>
  <li> time_since_last: Temps écoulé depuis le dernier événement </li>
  <li> last_distance: Distance entre l'événement présent et le dernier événement </li>
  <li> rebound: Indique si le dernier événement est 'Shot' ou non </li>
  <li> change_angle: Différence d'angle, en valeur absolue, entre l'événement présent et le dernier événement si ces deux événements sont 'Shot' </li>
  <li> speed: Ratio entre la distance parcourue et le temps écoulé depuis le dernier événement </li>
</ul>

[Voici le lien vers l'expérience qui stocke l'artefact DataFrame filtré](https://www.comet.com/jhd/project-ds-ift6758-a23-2/db728064293b44c6ba4cc1acacf2bacf?experiment-tab=assetStorage)

## 5. Modèles avancés

#### 5.1 XGBoost avec les caractéristiques des base
Nous avons premièrement entraîné un modèle XGBoost en n'utilisant que les caractéristiques de distance et d'angles, comme nous l'avons fait précédemment avec nos modèles de base.

#### 5.2 XGBoost avec nos nouvelles caractéristiques et avec des hyperparamètres optimisés
Nous avons ensuite entraîné un modèle XGBoost avec les caractéristiques créées dans la section 4. Nous avons créé une fonction se servant d'un hypercube latin afin de trouver le meilleur choix d'hyperparamètres. Notre meilleure combinaison d'hyperparamètres maximise les résultats obtenus pour les métriques de balanced accuracy, de f1 weighted, de recall_weighted et de roc auc. Voici les hyperparamètres sélectionnés:

<ul>
  <li>learning_rate: 0.726847</li>
  <li>n_estimators: 70</li>
  <li>max_depth: 42</li>
  <li>min_child_weight: 10</li>
  <li>subsample: 0.91968</li>
  <li>colsample_bytree: 0.228184</li>
  <li>reg_alpha: 0.650468</li>
  <li>max_delta_step: 4</li>
  <li>min_split_loss: 7.684902</li>
</ul>

#### 5.3 XGBoost avec sélection de caractéristiques
Nous nous sommes servis de différentes méthodes afin de déterminer l'importance de nos caractéristiques. Nous avons utilisé la librairie eli5 afin d'obtenir une première mesure sur l'importance des caractéristiques.

![eli5](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/eli5_2.jpg)

Les caractéristiques d'importances sont emptyNet, last_x, last_distance, change_angle et angle. 

![emptyNet](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/emptyNet_plot.png)

Il est évident que de savoir si un but est vide ou non est un indicateur fort pour nos prédictions. Le graphique précédent nous montre qu'un but vide résulte plus souvent en un but. Dans le cas où le gardien est devant le filet cependant, nous n'obtenons aucune information pertinente. Notre caractéristique est alors sans importance.

![last_x](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/last_x_plot.png)

La caractéristique last_x fait référence à la position en x de la dernière action. Il semble que les actions menées au coeur de la patinoire (autour de la ligne du centre) sont les plus déterminantes pour prédire un but à venir.

![last_distance](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/last_distance_plot.png)

Il semble aussi que plus l'action précédente a eu lieu à une faible distance de l'action présente, plus celle-ci augmente l'importance de la caractérisque last_distance.

![shap0](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/shap_0.jpg)

Nous avons également effectué une analyse avec shap. Nous voyons qu'un tir rapproché effectué à 15.3 pieds du but augmenter les chances de marquer. Dans notre cas, lorsque last_event est égal à 1 cela signifie que le dernier événement était un but. Ainsi, nous voyons que lorsque le dernier événement était un but, cela diminue les chances que l'événement présent soit aussi un but. Ce résultat est logique, puisqu'après un but le jeu arrête, puis reprend au centre de la patinoire. 

Par ailleurs, nous nous sommes posés la question à savoir si notre test eli5 arrivait réellement à juger de l'importance des caractéristiques. Nous avons donc sélectionné 8 caractéristiques sur les 12 que nous avions évalué précédemment afin de créer un nouveau classement. Nous avons entre autres enlevé emptyNet, car bien qu'un filet vide soit un indicateur fort pour nos prédictions, il s'agit d'un événement rare. La figure ci-bas montre nos résultats.

![eli5](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/eli5.jpg)

Notre analyse effectuée avec notre modèle XGBoost entraîné sur les 8 caractéristiques listées dans la figure ci-haut indique que "time_since_last", "goal_distance" et "speed" sont nos trois caractéristiques les plus importantes. Il est intéressant de noter que cette fois-ci, last_x et last_distance sont relativement bas dans le classement. Nous avons effectué une analyse d'indépendance partielle sur nos trois premières caractéristiques.

![time_since_last](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/time_since_last_plot.png)

Nous voyons que lorsque moins de 5 secondes se sont écoulées depuis le dernier événement, l'importance de la caractéristique "time_since_last" est très forte pour nos prédictions. Une explication plausible serait que plusieurs tirs effectués rapidement l'un à la suite de l'autre sont plus difficiles à arrêter pour un gardien de but et augmentent ainsi la chance de marquer un but. 

![goal_distance](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/goal_distance_plot.png)

Nous voyons que plus un tir est effectué près d'un but, plus la distance est importante comme caractéristique. Les tirs rapprochés ont plus de chance de résulter en un but comme nous l'avons vu dans le milestone 1. Ce graphique rejoins donc l'analyse que nous avions formulée initialement.

![speed](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/speed_plot.png)

Le "speed" est défini comme comme la distance depuis l'événement précédent, divisée par le temps écoulé depuis l'événement précédent. Notre graphique est difficile à interpréter. En effet, on pourrait supposer que des tirs qui se suivent rapidement dans le temps et dans l'espace ont plus de chance de résulter en un but. Au contraire, on pourrait supposer que des tirs qui ne se suivent pas rapidement dans le temps et dans l'espace ont moins de chance de résulter en un but. 

![eli5](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/public/milestone_2/shap.jpg)

Nos valeurs shap montrent qu'une faible distance par rapport au but (goal_distance) augmente la probabilité d'un but. Un angle de 131.6 degrés diminue la probabilité qu'un tir résulte en un but, ce qui est logique puisque la surface du filet qui peut être atteinte par un tir diminue quand l'angle s'éloigne de 90 degrés.

Ceci nous amène à un autre entraînement que nous avons effectué. Nous avons décider de garder  4 de nos caractéristiques de départ, soit 'emptyNet', 'last_distance', 'change_angle' et 'angle'. Nous avons sélectionné les hyperparamètres choisis en 5.2.

Note pour lire les graphiques (avec liens vers l'expérience sur Comet):

- [1.0.0 : classificateur aléatoire](https://www.comet.com/jhd/project-ds-ift6758-a23-2/f1aad054759d4eacb797fd6cefbe1d02)
- [1.1.0 : XGBoost, entraîné sur la distance uniquement](https://www.comet.com/jhd/project-ds-ift6758-a23-2/2230b905d0bc4bd18c54cc0b25f935b3)
- [1.2.0 : XGBoost, entraîné sur l'angle uniquement](https://www.comet.com/jhd/project-ds-ift6758-a23-2/23ffe7d490524028aaeac93874f7cd5e)
- [1.3.0 : XGBoost, entraîné sur la distance et l'angle](https://www.comet.com/jhd/project-ds-ift6758-a23-2/a7025a692ee94224a0bc13c2870c26bd)
- [1.4.0 : XGBoost, entraîné sur nos caractéristiques trouvées en 4](https://www.comet.com/jhd/project-ds-ift6758-a23-2/dbdb002ee7c448e997611c9e6f9ef7fa)
- [1.5.0 : XGBoost, entraîné sur nos caractéristiques trouvées en 4 et avec des hyperparamètres optimisés](https://www.comet.com/jhd/project-ds-ift6758-a23-2/dc72d18181614ce4a0221c10ae366349)
- [1.6.0 : XGBoost, entraîné sur nos caractéristiques trouvées en 4, avec des hyperparamètres optimisés et avec une sélection des caractéristiques](https://www.comet.com/jhd/project-ds-ift6758-a23-2/c95b3e4c126d46fb9c764281150c0e3f)


![image](https://s3.amazonaws.com/comet.ml/image_5ba4d92649f146b3bfe00c420b786687-6j9PIJLNX8ItXWxbtrEwF1wWt.svg)
![image](https://s3.amazonaws.com/comet.ml/image_5ba4d92649f146b3bfe00c420b786687-zXKieRVIjDdMXhR8kcK2UrDI1.svg)
![image](https://s3.amazonaws.com/comet.ml/image_5ba4d92649f146b3bfe00c420b786687-lVXvKjhDWeLHTErd3RWQOqw24.svg)
![image](https://s3.amazonaws.com/comet.ml/image_5ba4d92649f146b3bfe00c420b786687-fwTArIumXRkR6PinOB0EhLmfg.svg)
![image](https://s3.amazonaws.com/comet.ml/image_5ba4d92649f146b3bfe00c420b786687-Ysqr2dvyEkF3SUeGSxHvUCYIG.svg)

Tous nos modèles performent mieux que notre baseline aléatoire, ce qui est un bon signe. Cependant, nous voyons que notre modèle "final" (1.6.0) performe moins  bien que tous nos modèles à l'exception du modèle 1.2.0. Peut-être qu'avec moins de caractéristiques, même si celles-ci ont été filtrées pour leur pertinence, notre modèle XGBoost performe moins bien. Nous voyons par ailleurs que notre sélection d'hyperparamètres a amélioré les performances de notre modèle sur toutes les métriques.

## 6. Meilleur modèle (Faites de votre mieux!)

#### [Modèle 1](https://www.comet.com/jhd/project-ds-ift6758-a23-2/9d35f307e940438a9c49c95e841ea83d)
Nous avons tenté d'optimiser un modèle de Random Forest Classifier en utilisant une méthode de sélection des caractéristique vue en classe. Nous avons en effet en effet implémenté une méthode d'encapsulation de type recherche vers l'avant. Pour ce faire, nous avons sélectionné la meilleure caractéristique parmi 16 caractéristiques en se basant sur un score de f1 weighted. En effet, comme nous l'avons déjà mentionné, l'accuracy n'est pas la meilleure métrique dans notre cas. Ensuite, nous avons tenté de trouver la caractéristique qui optimisait le f1 weighted dans un entrainement effectué en combinaison avec la première caractéristique. Nous avons procéder de la sorte pour trouver 6 caractéristiques. Les 6 caractéristiques ainsi sélectionnées sont les suivantes : emptyNet', 'y', 'x', 'periodTimeRemaining', 'speed' et 'time_since_last'.

#### [Modèle 2](https://www.comet.com/jhd/project-ds-ift6758-a23-2/ac633acccb2e4e44b75891b39badcda3)
Comme deuxième modèle, nous avons construit un classifieur dont les prédictions de probabilités sont déterminées par la moyenne (possiblement pondérée) de deux modèles XGBoost différents (soft voting). Ces deux modèles XGBoost se distinguent l'un de l'autre à travers la différence dans les hyperparamètres et random states utilisés durant leur entrainement respectif. Pour ce faire, nous avons commencé par remplacer les valeurs manquantes et les valeurs infinies par 0. Nous avons essayé de remplacer celles-ci par le mode, la médiane ou la moyenne des distributions respectives, mais les modèles résultants performaient moins bien que si on remplaçait par 0. Nous avons aussi utilisé l'encodage d'étiquette sur la variable 'shot_type'. Ensuite, dans un premier temps, au niveau de la sélection de caractéristiques nous avons procédé en entrainant un modèle XGBoost avec hyperparamètres standard à l'exception du scale_pos_weight qui a été fixé à 10. Puis, nous avons regardé à la fois l'importance des caractéristiques produite par ce modèle, l'importance par permutation des caractéristiques résultante de ce modèle et la matrice de corrélations des caractéristiques pour éviter la redondance. Les visualisations de ces métriques sont explicitées ci-dessous:


![image](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/_includes/Feat_imp_voting_algo.png)
![image](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/_includes/Feat_perm_voting_algo.png)
![image](https://raw.githubusercontent.com/julien-hebert-doutreloux/Project-Blog-IFT6758-A23/main/_includes/Corr_Heatmap_voting_algo.png)

On remarque qu'on a inclut dans nos données une variable aléatoire qui nous permet de mettre de côté certaines caractéristiques négligeables.  Ainsi, à partir de ces 3 figures, nous avons pu réduire notre liste de caractéristiques à 8 caractéristiques: 'emptyNet', 'goal_distance', 'time_since_last',
'angle', 'y', 'shot_type', 'last_distance' et 'speed'. Une fois cette liste de caractéristiques finale obtenues, nous avons roulé deux fois, avec des états aléatoires différents, la recherche d'hyperparamètre par hypercube latin en combinaison avec la validation croisée (sur l'ensemble d'entrainement) afin de trouver les hyperparamètres optimaux de chacun des deux modèles XGBoost. Finalement, nous avons reséparé les données et réentrainer le modèle combiné (les deux XGBoost) pour pouvoir produire les métriques de validations de celui-ci. Les prédictions utilisées pour les métriques de validation ont été obtenues en effectuant la moyenne exact des prédictions de probabilités des deux modèles. Celui-ci a bien performé par rapport au modèle précédent. Entre autres, il a obtenu un ROC AUC score de 0.76. 

#### [Modèle 3](https://www.comet.com/jhd/project-ds-ift6758-a23-2/1c28aad77b27441fa85820f482ac8fcc)
Le troisième modèle que nous avons construit est un simple modèle XGBoost dont les caractéristiques ont été sélectionnées en utilisant la méthode SelectKBest de sklearn. Avant de passer à la sélection de charactéristiques, nous avons appliqué un minmax scaler sur les variables 'x', 'y', 'last_x', 'last_y', 'goal_distance', 'last_distance', 'angle', 'change_angle', 'speed' et nous effectué le même traitement que dans le modèle précédant. Concernant la sélection de caractéristiques, nous avons sélectionné les 7 meilleurs caractéristiques à l'aide de SelectKBest, l'hyperparamètres k=7 de SelectKBest a été déterminé avec une recherche en grille. Les caractéristiques sélectionnées sont les suivantes: 'x', 'y', 'last_x', 'last_y', 'goal_distance', 'last_distance', 'angle', 'change_angle', 'speed'. Puis, une fois cette liste de caractéristiques finale obtenues, nous avons roulé la recherche d'hyperparamètre par hypercube latin en combinaison avec la validation croisée (sur l'ensemble d'entrainement) afin de trouver les hyperparamètres optimaux pour ce modèle XGBoost.

#### Modèle surprise :)
Nous avons également tenté une quatrième expérience plus ludique. Nous avons pris les données de chaque événement et nous les avons reformulées sous la forme de phrases, tel qu'un commentateur sportif aurait pu les formuler. Par exemple, "Backhand by Bobby Ryan at 7 feet from the net". Nous avons ensuite entrainé un modèle de langue de type BERT sur ces données textuelles. Les résultats ne sont pas concluants, tel que démontré ci-bas:

True negatives: 52064
True positives: 24
False positives: 34
False negatives: 5608
TOTAL: 57730

Ces résultats sont entre autres dû au débalancement des classes dans le jeu de données brutes. Comme nous l'avons mentionné, 90% des tirs ne résultent pas en but. Puisqu'il s'agit d'un événement rare, notre modèle produit beaucoup de faux négatifs. Par ailleurs, les données que nous donnons à notre modèle sont plus limitées.

### Même si notre modèle ensembliste obtient la meilleure performance, nous considérons que notre meilleur modèle est XGBoost avec SelectKBest, car il est plus simple à évaluer sur l'ensemble de test et sa performance est assez similaire.

![image](https://s3.amazonaws.com/comet.ml/image_b2b86d1f854f42a5bd2517c0dc7e77d8-6rATxLaCQHCBeJQhhHxqtfgpS.svg)
![image](https://s3.amazonaws.com/comet.ml/image_b2b86d1f854f42a5bd2517c0dc7e77d8-aYNkocdAA7c4RQ0x7T4a7RhLR.svg)
![image](https://s3.amazonaws.com/comet.ml/image_b2b86d1f854f42a5bd2517c0dc7e77d8-BobPkbGLeEGcoisywMBn1pdyG.svg)
![image](https://s3.amazonaws.com/comet.ml/image_b2b86d1f854f42a5bd2517c0dc7e77d8-gU4RLAsoYZw28wg9R7T6ozoRV.svg)
![image](https://s3.amazonaws.com/comet.ml/image_b2b86d1f854f42a5bd2517c0dc7e77d8-OYSUWZuhMxPQeyRbJ9iIyGCRl.svg)

## 7. Évaluer sur l'ensemble de test

#### [Test sur la saison régulière 2020-2021](https://www.comet.com/jhd/project-ds-ift6758-a23-2/5c1c4224730248a5aa7fbfd96e430bba)
![image](https://s3.amazonaws.com/comet.ml/image_5c1c4224730248a5aa7fbfd96e430bba-umF6iq0inaq7yZZsivUHuJ3tk.svg)
![image](https://s3.amazonaws.com/comet.ml/image_5c1c4224730248a5aa7fbfd96e430bba-zNA4lfNckDrck9RXAYDPy9hx5.svg)
![image](https://s3.amazonaws.com/comet.ml/image_5c1c4224730248a5aa7fbfd96e430bba-pgju5tpSgHoySj6O7DGfInfqI.svg)
![image](https://s3.amazonaws.com/comet.ml/image_5c1c4224730248a5aa7fbfd96e430bba-7UL8M1cc8lIXAemhyyiON6Axd.svg)
![image](https://s3.amazonaws.com/comet.ml/image_5c1c4224730248a5aa7fbfd96e430bba-s3PLwdhrRzfQCoLzHPrwVqOt5.svg)

Nous voyons que notre meilleur modèle XGBoost et que notre meilleur modèle de la section "Faites de votre mieux" obtiennent une performance égale.
Nous voyons aussi que ces deux modèles performent mieux que nos modèle de régression logisitique. 

#### [Test sur les séries éliminatoires 2020-2021](https://www.comet.com/jhd/project-ds-ift6758-a23-2/7f1db70f3f3545e4bd57b4fe7de2d85a)

![image](https://s3.amazonaws.com/comet.ml/image_7f1db70f3f3545e4bd57b4fe7de2d85a-8Qv0ymVFRybhX2ChMmdeTcKRJ.svg)
![image](https://s3.amazonaws.com/comet.ml/image_7f1db70f3f3545e4bd57b4fe7de2d85a-eRGdZltH1oPTSjZ6YlTgd0l4I.svg)
![image](https://s3.amazonaws.com/comet.ml/image_7f1db70f3f3545e4bd57b4fe7de2d85a-7T3V0PhZxj4iNCPM6O5fq84vC.svg)
![image](https://s3.amazonaws.com/comet.ml/image_7f1db70f3f3545e4bd57b4fe7de2d85a-yyZ6soFY2Xj6IAKwLgxuGM0z6.svg)
![image](https://s3.amazonaws.com/comet.ml/image_7f1db70f3f3545e4bd57b4fe7de2d85a-vQdN5y7tgTKV3R1lRoTpLxQJg.svg)

Les résultats obtenus en testant sur les séries éliminatoires sont semblables à ceux obtenus pour les tests effectués sur les saisons régulières.

Pour conclure, les résultats obtenus sont semblables à ce à quoi nous nous attendions. Les modèles XGBoost optimisés performent mieux que nos modèles de régression logistique. En effet, les données ne sont pas linéairement séparables, ce qui rend notre modèle de régression logistique moins apte à faire de bonnes prédictions pour notre tâche. Nos optimisations sur XGBoost ont porté fruit, autant dans la section des modèles avancés que dans la section "faites de votre mieux". 
